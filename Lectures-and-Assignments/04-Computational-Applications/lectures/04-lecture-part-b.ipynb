{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math  1376: Programming for Data Science\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # We will use numpy in this lecture\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "from matplotlib.patches import Polygon \n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 04: Some useful applications of Modules 01-03\n",
    "---\n",
    "\n",
    "In this module, we will now pull together material across our first three modules to solve some practical problems. \n",
    "\n",
    "You may find it useful to review the notebooks in those modules beforehand or just simply open some of the notebooks to have their contents available to review as necessary. \n",
    "\n",
    "While there are a seemingly endless number of practical problems we can attempt to solve with what we have learned so far, we will focus on three ubiquitous problems in the computational sciences.\n",
    "\n",
    "- Root-finding. (The content of Part (a) of this module.)\n",
    "\n",
    "- Numerical integration. (The content of Part (b) of this module.)\n",
    "\n",
    "- Optimization. (This content is pursued in the assignments of this module.)\n",
    "\n",
    "\n",
    "### A note about calculus concepts and interactive visualizations (i.e., widgets)\n",
    "---\n",
    "\n",
    "These topics are commonly studied as applications of calculus concepts. \n",
    "However, while we may make passing reference to certain calculus concepts, you do *not* need to know calculus to follow the narratives. (This, of course, is not to say that you should not seek to master calculus at some point.)\n",
    "Our focus is on the *big picture ideas* and we use interactive graphics (powered by a widgets module) to help us explore these ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives for Part (b)\n",
    "\n",
    "- Understand what integration means and how it arises in practical applications.\n",
    "\n",
    "\n",
    "- Implement different types of numerical integration algorithms to various functions written either as `lambda` Python functions or more complicated user-defined functions.\n",
    "\n",
    "\n",
    "- Create code that implements numerical integration algorithms of different types.\n",
    "\n",
    "\n",
    "- Create annotations and interactive widgets to enhance visualizations of data.\n",
    "\n",
    "\n",
    "### Some larger \"in situ\" learning objectives (i.e., learning that will occur by design of activities)\n",
    "\n",
    "While we are going to explore how to implement some of these algorithms as activities below, our learning objectives go beyond simple correct implementation. We will also consider what it means to do the following:\n",
    "\n",
    "- *compare* and *analyze* different algorithms developed for solving the same generic problem;\n",
    "\n",
    "- use this comparison to *choose* the \"right\" algorithm for solving a *specific* problem;\n",
    "\n",
    "- create a module (in the external activity) that encodes various algorithms and a *wrapper* function that automatically chooses which algorithm to apply based on the inputs.\n",
    "\n",
    "Some of this is done in the notebook while other parts are left for homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook contents <a id='Contents'></a>\n",
    "\n",
    "* <a href='#Integration'>Part (b): Numerical integration</a>\n",
    "\n",
    "    * <a href='#concepts'>Part (b)(i): The basic concepts of integration</a>\n",
    "\n",
    "    * <a href='#numerical-integration'>Part (b)(ii): Numerical integration algorithms</a>\n",
    "\n",
    "        * <a href='#activity-rectangle-rules'>Activity: Rectangle rules</a>\n",
    "\n",
    "        * <a href='#activity-MC'>Activity: Monte Carlo integration</a>\n",
    "\n",
    "        * <a href='#activity-MC-darts'>Activity: Integration over the dart board</a>\n",
    "\n",
    "    * <a href='#activity-summary'>Activity: Summary</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b): Numerical integration <a id='Integration'>\n",
    "---\n",
    "\n",
    "**Expected time to completion: 6-9 hours**    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b)(i): The basic concepts of integration <a id='concepts'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:rgba(255,255,0, 0.25); color:black'> Run the code cell below and click the \"play\" button to see the first recorded lecture associated with this notebook.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Running this cell will embed the short recorded lecture associated with this part of the notebook\n",
    "# 2. Press on the \"play\" button to start the video.\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('Fd58TZj6M2w', width=800, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is it and why should we care?\n",
    "\n",
    "What *the integral* of a function means can depend a bit on context, which also helps to explain the *why* of an integral. \n",
    "Typically, it refers to transforming a function into a scalar quantity that describes some type of important aggregate behavior of the function over a set.\n",
    "It is *kind of like* summing up the behavior of a function over a set in order to make important inferences. \n",
    "Some examples of what integrals mean in different contexts are given below. \n",
    "\n",
    "- In probability theory, the functions that quantify scalar outputs of an experiment are called random variables. \n",
    "The integrals of random variables weighted by their probability density functions give the expected value of the experiment.\n",
    "Other standard statistical quantities such as variance also involve integrals.\n",
    "\n",
    "- In engineering design and manufacturing processes, it is often important to compute the length of a curve, the area of a region, or the volume of an object (e.g. to determine the amount of resources/cost in constructing an object). Such quantities are given by integrals.\n",
    "\n",
    "- In physics, integrals are used to determine important quantities like velocity (which is given as an integral of acceleration) and displacement (an integral of velocity). \n",
    "\n",
    "- In finance, integrals are sometimes used to determine options pricing.\n",
    "\n",
    "\n",
    "- Many models of complex physical phenomena involve partial differential equations that are solved via numerical methods (e.g., finite element methods) that require computations of many integrals to construct accurate approximations. \n",
    "\n",
    "\n",
    "- In data science, statistical/machine learning, and any other data-driven discipline where proposed models are *fitted* to data, the *goodness of fit* of a model can usually be described in terms of an integral (or its discrete counterpart: summation). \n",
    "\n",
    "<span style='background:rgba(255,0,255, 0.25); color:black'> ***Notation:*** <span>\n",
    "\n",
    "There are a few different notational conventions, but here we will use the following: Let $f(x)$ be a function and $A\\subset dom(f)$ (i.e., $A$ is some set of acceptable inputs taken from the domain of the function $f$), then the integral of $f$ over $A$ is denoted by\n",
    "\n",
    "$$\n",
    "  \\large  \\int_A f(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### A standard motivating example\n",
    "\n",
    "We are going to avoid any complicating calculus details.\n",
    "But, to build intuition, we are going to consider some simple examples that also serve to make all of this less abstract and more concrete. \n",
    "\n",
    "<span style='background:rgba(255,0,255, 0.25); color:black'> ***General details:*** <span>\n",
    "\n",
    "- Suppose $v(t)$ describes the velocity of an object moving either forward/backward on some path over the time interval $[t_0,t_f]$ (here $t_0$ denotes an initial time and $t_f$ denotes the final time).\n",
    "\n",
    "- Suppose we are interested in how far along the path the object ultimately ends up relative to its starting position, which is given by\n",
    "\n",
    "$$\n",
    "  \\large  \\int_{[t_0,t_f]} v(t)\n",
    "$$\n",
    "\n",
    "<span style='background:rgba(255,0,255, 0.25); color:black'> ***Examples with intuitive solutions:*** <span>\n",
    "\n",
    "For simple functions of $v(t)$, we can easily conceptualize the problem and intuit the solution with little difficulty (i.e., without referring to anything from calculus). Consider the following scenarios:\n",
    "\n",
    "- $v(t)=0$ (i.e., the object is not moving). \n",
    "\n",
    "    - Then, $\\int_{[t_0,t_f]} v(t) = 0$, which means the final displacement of the object from its initial position is zero units of length. Not surprising. The object did not move.\n",
    "\n",
    "    \n",
    "- Suppose now that\n",
    "    \n",
    "$$\n",
    "    v(t) = \\begin{cases}\n",
    "                5, & t_0<t<\\frac{t_f+t_0}{2}, \\\\\n",
    "                -5, & \\frac{t_f+t_0}{2}<t<t_f,\n",
    "            \\end{cases}\n",
    "$$\n",
    "    \n",
    "which simply means that the object is moving forward at a constant speed of 5 (ignoring units) for half the time and then moving at the same speed *but backwards* (i.e., in the other direction) the other half of time. \n",
    "\n",
    "  - Then, $\\int_{[t_0,t_f]} v(t) = 0$ because the object just did a simple \"round trip\" back to where it started. \n",
    "\n",
    "\n",
    "\n",
    "- Suppose we have the same velocity as the previous example, but we instead we wanted to know the *total distance* traveled instead of just the final displacement from the starting position? Then, we would want to know $$\\large \\int_{[0,t_f]} \\vert v(t) \\vert$$ which means we want to integrate the absolute value of velocity. \n",
    "   <br><br>\n",
    "   \n",
    "   But, what is $\\int_{[t_0,t_f]}\\vert v(t) \\vert$?\n",
    "   <br><br>\n",
    "   \n",
    "   In this case, we know that this means we are integrating a function that is constant over all time (in this case a constant 5). If an object moves at a constant *speed* (speed is the absolute value of velocity), then we should be able to figure out the total distance it traveled. This is easier when considering units. Suppose $v(t)$ is described in miles per hour, which we rewrite as $\\frac{\\text{miles}}{\\text{hour}}$. It sure seems like if we just multiplied by the total number of hours the object was moving, then we would get the total number of miles the object traveled because \n",
    "   \n",
    "   $$\n",
    "       \\frac{\\text{miles}}{\\text{hour}}\\text{hour} = \\text{miles},\n",
    "   $$\n",
    "   \n",
    "    i.e., the \"hours cancel out.\"\n",
    "   <br><br>\n",
    "   \n",
    "   So, in this example, $\\int_{[t_0,t_f]} \\vert v(t) \\vert = 5(t_f-t_0)$.\n",
    "   <br><br>\n",
    "   \n",
    "   Let's visualize these last two results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v(t,t_f):\n",
    "    n = len(t)\n",
    "    vs = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        if t[i]<t_f/2:\n",
    "            vs[i] = 5\n",
    "        else:\n",
    "            vs[i] = -5\n",
    "    return vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_0 = 0\n",
    "t_f = 10  # integral limits\n",
    "t = np.linspace(t_0, t_f)\n",
    "\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(num=0)\n",
    "ax.plot(t, np.abs(v(t,t_f)), 'r', linewidth=2)\n",
    "ax.set_ylim(bottom=0)\n",
    "\n",
    "# Make the shaded region associated with the integral\n",
    "it = np.linspace(t_0, t_f)\n",
    "iv = np.abs(v(it,t_f))\n",
    "verts = [(t_0, 0), *zip(it, iv), (t_f, 0)]\n",
    "poly = Polygon(verts, facecolor='0.9', edgecolor='0.5')\n",
    "ax.add_patch(poly)\n",
    "\n",
    "ax.text(0.5 * (t_0 + t_f), 2.5, r\"$\\int_{[t_0,t_f]} \\vert v(t)\\vert=5(t_f-t_0)$\",\n",
    "        horizontalalignment='center', fontsize=20)\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.set_xticks((t_0, t_f))\n",
    "ax.set_xticklabels(('$t_0$', '$t_f$'), fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_0 = 0\n",
    "t_f = 10  # integral limits\n",
    "t = np.linspace(t_0, t_f, 101)\n",
    "\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(num=1)\n",
    "ax.plot(t, v(t,t_f), 'r', linewidth=2)\n",
    "\n",
    "# Make the shaded region associated with the integral\n",
    "it = np.linspace(t_0, t_f, 101)\n",
    "iv = v(it,t_f)\n",
    "verts = [(t_0, 0), *zip(it, iv), (t_f, 0)]\n",
    "poly = Polygon(verts, facecolor='0.9', edgecolor='0.5')\n",
    "ax.add_patch(poly)\n",
    "\n",
    "ax.text(0.75 * (t_0 + t_f), 2.5, r\"$\\int_{[t_0,t_f]} v(t)=0$\",\n",
    "        horizontalalignment='center', fontsize=20)\n",
    "\n",
    "ax.axhline(0, linewidth=1, c='k')  # plot $v=0$ line to more clearly demonstrate the positive/negative parts\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.set_xticks((t_0, t_f))\n",
    "ax.set_xticklabels(('$t_0$', '$t_f$'), fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we see?\n",
    "\n",
    "- It appears that these integrals are related to the *areas* of the shaded rectangles. \n",
    "\n",
    "    In particular, $\\int_{[t_0,t_f]} |v(t)|$ is exactly the area of the single shaded rectangle.\n",
    "\n",
    "\n",
    "- On the other hand, $\\int_{[t_0,t_f]} v(t)$ is given by the area of the rectangle above the $t$-axis *minus* the area of the rectangle below the $t$-axis. They appear to *cancel* each other out. In fact, if we think of areas as being *signed* so that any area above a horizontal axis is positive and any area below the horizontal axis is negative, then we see that $\\int_{[t_0,t_f]} v(t)$ is actually the sum of the *signed* areas. \n",
    "\n",
    "\n",
    "- These observations actually lead us to a useful conceptualization of integrals in terms of \"sizes\" of positive and negative regions of a function over a set. \n",
    "\n",
    "Below, we visualize what the sign of an integral is for a function in terms of what dominates: the positive or negative areas `quad` function to compute accurate approximations of the integral.\n",
    "\n",
    "<span style='background:rgba(255,0,255, 0.25); color:black'> ***Key takeaways about `quad`:*** </span>\n",
    "\n",
    "- The `quad` function is within the `integrate` subpackage of `scipy`, and you should take at least 5-10 minutes to review some of the documentation https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.quad.html\n",
    "\n",
    "- The `quad` function returns a tuple as an output (much like our `compute_bisection` function from the previous lecture notebook). \n",
    "The first component is the approximation of the integral. The second component is an approximation of the error in the integral. Therefore, we usually append a `[0]` to the end of it whenever we are just interested in the actual approximation of the integral (you should take note of this below).\n",
    "\n",
    "- If you peruse the source code for the `quad` function, then you will see some nice docstrings, doctests, etc. https://github.com/scipy/scipy/blob/v1.5.3/scipy/integrate/quadpack.py#L49-L442\n",
    "\n",
    "The `integrate` subpackage is itself rather interesting and useful to familiarize yourself with: https://docs.scipy.org/doc/scipy/reference/tutorial/integrate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_integral(f, x_min, x_max, a, b, fignum=0):\n",
    "    # Estimate the integral with quad function\n",
    "    # The quad returns a tuple and the first component is\n",
    "    # the estimate of the integral we are after\n",
    "    int_ab = quad(f, a, b)[0] \n",
    "    \n",
    "    #### EVERYTHING ELSE BELOW IS JUST PLOTTING\n",
    "    x = np.linspace(x_min, x_max, 101)\n",
    "    y = f(x)\n",
    "\n",
    "    plt.figure(num=fignum)\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(num=fignum)\n",
    "    ax.plot(x, y, 'r', linewidth=2)\n",
    "\n",
    "    plt.axhline(0, linewidth=1, linestyle=':', c='k')  # plot typical x-axis\n",
    "    \n",
    "    # Make the shaded region\n",
    "    ix = np.linspace(a, b, 101)\n",
    "    iy = f(ix)\n",
    "    # A * before the zip will \"unpack\" the tuples in the \n",
    "    # list of tuples created by zip\n",
    "    verts = [(a, 0), *zip(ix, iy), (b, 0)]\n",
    "    poly = Polygon(verts, facecolor='0.9', edgecolor='0.5')\n",
    "    ax.add_patch(poly)\n",
    "    \n",
    "    ax.set_title(r\"$\\int_a^b f(x)\\mathrm{d}x \\approx $ %3.2f\" %int_ab, fontsize=10)\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.set_xticks((a, b))\n",
    "    ax.set_xticklabels(('$a$', '$b$'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f out\n",
    "\n",
    "%matplotlib widget\n",
    "interact_manual(plot_integral, \n",
    "         f = widgets.fixed(lambda x: (x + 1) * (x - 5) * np.sin(3*x)),\n",
    "         x_min = widgets.fixed(-1),\n",
    "         x_max = widgets.fixed(5),\n",
    "         a = widgets.FloatSlider(value=2, min=-1, max=5, step=0.1),\n",
    "         b = widgets.FloatSlider(value=4, min=-1, max=5, step=0.1),\n",
    "         fignum = widgets.fixed(0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating an `Integration` class.**\n",
    "\n",
    "<span style='background:rgba(0,255,255, 0.5); color:black'> Suggested activity:</span> \n",
    "- Add docstrings to the `Integration` class below.\n",
    "\n",
    "- Add code comments to this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Integration(object):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, f, a=None, b=None):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        self.f = f\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def set_integral_limits(self, a, b):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def evaluate_integral(self, a=None, b=None):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        if (a is not None) and (b is not None):\n",
    "            self.set_integral_limits(a, b)\n",
    "            \n",
    "        self.integral = quad(self.f, self.a, self.b)[0]\n",
    "        \n",
    "        return self.integral\n",
    "    \n",
    "    def plot_integral(self, x_min=None, x_max=None, N=101, fignum=0):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        if x_min is None:\n",
    "            x_min = self.a\n",
    "        \n",
    "        if x_max is None:\n",
    "            x_max = self.b\n",
    "            \n",
    "        x = np.linspace(x_min, x_max, N)\n",
    "        y = self.f(x)\n",
    "\n",
    "        plt.figure(num=fignum)\n",
    "        plt.clf()\n",
    "        fig, ax = plt.subplots(num=fignum)\n",
    "        ax.plot(x, y, 'r', linewidth=2)\n",
    "\n",
    "        plt.axhline(0, linewidth=1, linestyle=':', c='k')  # plot typical x-axis\n",
    "\n",
    "        # Make the shaded region\n",
    "        ix = np.linspace(self.a, self.b, N)\n",
    "        iy = self.f(ix)\n",
    "        # A * before the zip will \"unpack\" the tuples in the \n",
    "        # list of tuples created by zip\n",
    "        verts = [(self.a, 0), *zip(ix, iy), (self.b, 0)]\n",
    "        poly = Polygon(verts, facecolor='0.9', edgecolor='0.5')\n",
    "        ax.add_patch(poly)\n",
    "\n",
    "        ax.set_title(r\"$\\int_a^b f(x)\\mathrm{d}x \\approx $ %3.2f\" %self.integral, fontsize=10)\n",
    "            \n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.set_xticks((self.a, self.b))\n",
    "        ax.set_xticklabels(('$a$', '$b$'))\n",
    "        plt.show()\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def evaluate_and_plot_integral(self, a=None, b=None, x_min=None, x_max=None, fignum=0):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        self.evaluate_integral(a=a, b=b)\n",
    "        \n",
    "        self.plot_integral(x_min=x_min, x_max=x_max, fignum=fignum)\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_integral = Integration(lambda x: (x + 1) * (x - 5) * np.sin(3*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f out\n",
    "\n",
    "%matplotlib widget\n",
    "interact_manual(f_integral.evaluate_and_plot_integral, \n",
    "         x_min = widgets.fixed(-1),\n",
    "         x_max = widgets.fixed(5),\n",
    "         a = widgets.FloatSlider(value=2, min=-1, max=5, step=0.1),\n",
    "         b = widgets.FloatSlider(value=4, min=-1, max=5, step=0.1),\n",
    "         N = widgets.fixed(101), \n",
    "         fignum = widgets.fixed(0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context is everything and these are just 1-dimensional examples\n",
    "\n",
    "Above, we have just looked at functions with univariate inputs. Subsequently, we observed that the integral is related to the *signed* area between the curve defined by the function and the axis defined by the input.\n",
    "\n",
    "\n",
    "This observation can be conceptually extended to functions with multivariate inputs. Suppose $f(x)$ is a real-valued function, but $x=(x_1,x_2)$ is a point in $\\mathbb{R}^2$. Then, for a set $A\\subset\\mathbb{R}^2$, the integral $\\int_A f(x)$ is related to the *signed volume* between the *surface* given by the graph of $f(x)$ over $A$ and the horizontal *plane* defined by the 2-dimensional input.\n",
    "\n",
    "Generalizing the concept of area/volume is necessary to describe integrals in geometric terms when the inputs are three-dimensional or higher. \n",
    "\n",
    "We can pretty much stick with 1-dimensional examples to explore the typical numerical algorithms used to estimate integrals although some of the strengths and weaknesses of these algorithms are not apparent until we get to higher dimensions. Keep that in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b)(ii): Numerical Integration <a id='numerical-integration'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:rgba(255,255,0, 0.25); color:black'> Run the code cell below and click the \"play\" button to see the first recorded lecture associated with this notebook.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Running this cell will embed the short recorded lecture associated with this part of the notebook\n",
    "# 2. Press on the \"play\" button to start the video.\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('GyWZKfm6y2A', width=800, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of algorithms to perform numerical integration, e.g., see https://en.wikipedia.org/wiki/Numerical_integration.\n",
    "\n",
    "We focus on two basic types below. \n",
    "\n",
    "First, we consider geometric methods based upon rectangles. Then, we consider a stochastic form of integration called Monte Carlo integration. Monte Carlo methods are at the heart of many data science algorithms that rely upon some sort of stochastic implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric (deterministic) methods\n",
    "---\n",
    "\n",
    "Many of the deterministic approaches to estimating integrals are based on partitioning $A$ (i.e., cutting up the set $A$ into a non-overlapping collection of subsets although we allow for shared boundaries between the subsets) such that the signed \"areas\" (or \"volume\" or generalizations of volume) between the graph of $f(x)$ and these subsets drawn on the horizontal axis (or plane or hyperplane) defined by the inputs are well-approximated by a simple geometric object for which we know the area (or volume or generalization of volume).\n",
    "\n",
    "<span style='background:rgba(255,0,255, 0.25); color:black'> ***Key Points:*** <span>\n",
    "\n",
    "- The simplest such methods for 1-D problems involve the use of rectangles or trapezoids where the areas are easily computed from rules we learned in geometry.\n",
    "\n",
    "\n",
    "- When $A$ is simply an interval, we typically choose the partition of $A$ to be equally sized sub-intervals and approximate the signed area of $f(x)$ over each subinterval using a rectangle that is as wide as the sub-interval with height given by the evaluation of $f(x)$ at some point in the sub-interval. \n",
    "\n",
    "\n",
    "- Adding up all the signed areas of rectangles gives an approximation to the integral. This is visualized below where we provide some options about where we can evaluate the function $f(x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:rgba(0,255,255, 0.5); color:black'> Suggested activity:</span> Add a useful docstring to `compute_rect_rules` to describe the role of the various parameters. Add some doctests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rect_rules(f, a, b, n, rule='left'):\n",
    "    '''\n",
    "    Add a useful docstring here and doctest!\n",
    "    '''\n",
    "    ix = np.linspace(a, b, n+1)  # create the x-values to create the base of each rectangle \n",
    "    Delta_x = ix[1]-ix[0]  # compute the length of the base of each rectangle\n",
    "    \n",
    "    # Now determine the height of the rectangle by evaluating the\n",
    "    # function f at some point along its base.\n",
    "    if rule == 'left':\n",
    "        iy = f(ix[0:-1])  # evaluate function at left-hand side of its base\n",
    "    elif rule == 'right':\n",
    "        iy = f(ix[1:])  # evaluate the function at right-hand side of its base\n",
    "    else:\n",
    "        iy = f(ix[0:-1]+0.5*Delta_x)  # evaluate the function at midpoint of its base\n",
    "    \n",
    "    # Now compute the approximate integral by adding up all \n",
    "    # the areas of the rectangles\n",
    "    int_approx = np.sum(iy)*Delta_x\n",
    "    \n",
    "    return (ix, Delta_x, iy, int_approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Let's do some numerical experiments and analysis.***\n",
    "\n",
    "Below, we show how to\n",
    "\n",
    "1. Use the `compute_rect_rules` function defined above with the default rule.\n",
    "\n",
    "2. Analyze the rate of convergence (ROC).\n",
    "\n",
    "3. Create interactive visualizations of the `compute_rect_rules` function that help us tell a story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: (x + 1) * (x - 5) * np.sin(3*x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows how to use the lambda function f above as well as the default rule\n",
    "# to get an approximation\n",
    "int_approx = compute_rect_rules(f, a=2, b=4, n=10)[3]\n",
    "\n",
    "# Print the approximate integral\n",
    "print(int_approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To study the ROC for any approximation process, we usually vary critical inputs over orders of magnitude and employ log-log plots to understand how errors are reduced by refinement of the inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The logspace function is an easy way to create an array that varies over various orders of magnitude\n",
    "# The code below creates ns that go from 10**1 to 10**4\n",
    "ns = np.logspace(1, 4, num=4) \n",
    "print(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ns.dtype)  # Unfortunately, the compute_rect_rules requires the number of rectangles to be of type int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An easy fix\n",
    "ns = np.logspace(1, 4, num=4).astype('int')\n",
    "print(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a list of approximations for increasing number of rectangles\n",
    "int_approxes = []\n",
    "for n in ns:\n",
    "    int_approxes.append(compute_rect_rules(f, a=2, b=4, n=n)[3])\n",
    "print(int_approxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now compute the errors as a function of increasing number of rectangles\n",
    "errors_left_approx = np.array(int_approxes) - quad(f, a=2, b=4)[0]\n",
    "print(errors_left_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now visualize the convergence of the left-hand rule\n",
    "plt.figure()\n",
    "plt.loglog(ns, np.abs(errors_left_approx))\n",
    "plt.xlabel('# of rects.', fontsize=12)\n",
    "plt.title('Abs. Value of Errors vs. # of rects (left-hand rule)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to estimate the rate of convergence (ROC)?\n",
    "\n",
    "# The above curve is approximately a straight line. We therefore fit a line\n",
    "# of best fit below and report the slope of that line.\n",
    "\n",
    "ROC_estimate = np.polyfit(np.log(ns), np.log(np.abs(errors_left_approx)), 1)[0]\n",
    "\n",
    "# The slope of the line of best fit tells us how many orders of magnitude the error\n",
    "# is decreased for every order of magnitude increase in the number of rectangles.\n",
    "print(ROC_estimate) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now we do some fancier visualization.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rectangle_rules(f, a, b, n, rule='left', x_min=0, x_max=1, fignum=0):\n",
    "    # First get the approximation from a rectangle rule\n",
    "    ix, Delta_x, iy, int_approx = compute_rect_rules(f, a, b, n, rule)\n",
    "    \n",
    "    # Get a more accurate approximation from quad\n",
    "    # This is not necessary, but we use it for comparison sake\n",
    "    int_ab = quad(f, a, b)[0] \n",
    "    \n",
    "    ################# EVERYTHING BELOW IS JUST FOR PLOTTING\n",
    "    x = np.linspace(x_min, x_max, 101)\n",
    "    y = f(x)\n",
    "\n",
    "    plt.figure(num=fignum)\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(figsize=(10,10), num=fignum)\n",
    "    ax.plot(x, y, 'r', linewidth=2)\n",
    "\n",
    "    plt.axhline(0, linewidth=1, linestyle=':', c='k')  # plot typical x-axis\n",
    "    \n",
    "    rects = []\n",
    "    for i in range(n):\n",
    "        rects.append(Rectangle((ix[i],0), Delta_x, iy[i]))    \n",
    "    # Create patch collection with specified colour/alpha\n",
    "    pc = PatchCollection(rects, facecolor='0.9', alpha=0.5,\n",
    "                         edgecolor='0.5')\n",
    "    ax.add_collection(pc)\n",
    "   \n",
    "    ax.set_title(r\"$\\int_a^b f(x)\\mathrm{d}x = %3.2f \\approx $ Sum of Rect. Areas = %3.2f\" \n",
    "                 %(int_ab, int_approx), fontsize=20)\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.set_xticks((a, b))\n",
    "    ax.set_xticklabels(('$a$', '$b$'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f out\n",
    "\n",
    "%matplotlib widget\n",
    "interact_manual(plot_rectangle_rules, \n",
    "         f = widgets.fixed(lambda x: (x + 1) * (x - 5) * np.sin(3*x)),\n",
    "         a = widgets.FloatSlider(value=2, min=-1, max=5, step=0.1),\n",
    "         b = widgets.FloatSlider(value=4, min=-1, max=5, step=0.1),\n",
    "         n = widgets.IntSlider(value=3, min=1, max=50),\n",
    "         rule=['left', 'right', 'middle'],\n",
    "         x_min = widgets.fixed(-1),\n",
    "         x_max = widgets.fixed(5),\n",
    "         fignum=widgets.fixed(0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We visualize approximations of the integral for a different function below.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f out\n",
    "\n",
    "%matplotlib widget\n",
    "interact_manual(plot_rectangle_rules, \n",
    "         f = widgets.fixed(lambda x: x**2),\n",
    "         a = widgets.FloatSlider(value=0, min=-1, max=5, step=0.1),\n",
    "         b = widgets.FloatSlider(value=1, min=-1, max=5, step=0.1),\n",
    "         n = widgets.IntSlider(value=10, min=1, max=1000),\n",
    "         x_min = widgets.fixed(-1),\n",
    "         x_max = widgets.fixed(2),\n",
    "         rule=['left', 'right', 'middle'],\n",
    "         fignum=widgets.fixed(0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Let's make a `RectangleRule` `class` as a subclass of `Integration`.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectangleRule(Integration):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, f, a=None, b=None, n=None, rule='Left'):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        super().__init__(f=f, a=a, b=b)\n",
    "        self.n = n\n",
    "        self.rule = rule\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def change_rectangles(self, n=None, rule=None):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        if n is not None:\n",
    "            self.n = n\n",
    "        if rule is not None:\n",
    "            self.rule = rule\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def compute_integral_approx(self):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        self.ix = np.linspace(self.a, self.b, self.n+1)  # create the x-values to create the base of each rectangle \n",
    "        self.Delta_x = self.ix[1]-self.ix[0]  # compute the length of the base of each rectangle\n",
    "\n",
    "        # Now determine the height of the rectangle by evaluating the\n",
    "        # function f at some point along its base.\n",
    "        if self.rule == 'left':\n",
    "            self.iy = self.f(self.ix[0:-1])  # evaluate function at left-hand side of its base\n",
    "        elif self.rule == 'right':\n",
    "            self.iy = self.f(self.ix[1:])  # evaluate the function at right-hand side of its base\n",
    "        else:\n",
    "            self.iy = self.f(self.ix[0:-1]+0.5*self.Delta_x)  # evaluate the function at midpoint of its base\n",
    "\n",
    "        # Now compute the approximate integral by adding up all \n",
    "        # the areas of the rectangles\n",
    "        self.integral_approx = np.sum(self.iy)*self.Delta_x\n",
    "        \n",
    "        return self.integral_approx\n",
    "    \n",
    "    \n",
    "    def plot_rectangle_approx(self, x_min=0, x_max=1, N=101, fignum=0):\n",
    "        \n",
    "        # Get a more accurate approximate for comparison sake using method\n",
    "        # inherited from the super class and plot.\n",
    "        self.evaluate_integral()\n",
    "\n",
    "        ################# EVERYTHING BELOW IS JUST FOR PLOTTING\n",
    "        x = np.linspace(x_min, x_max, N)\n",
    "        y = self.f(x)\n",
    "\n",
    "        plt.figure(num=fignum)\n",
    "        plt.clf()\n",
    "        fig, ax = plt.subplots(num=fignum)\n",
    "        ax.plot(x, y, 'r', linewidth=2)\n",
    "        \n",
    "        plt.axhline(0, linewidth=1, linestyle=':', c='k')  # plot typical x-axis\n",
    "\n",
    "        rects = []\n",
    "        for i in range(self.n):\n",
    "            rects.append(Rectangle((self.ix[i],0), self.Delta_x, self.iy[i]))    \n",
    "        # Create patch collection with specified colour/alpha\n",
    "        pc = PatchCollection(rects, facecolor='0.9', alpha=0.5,\n",
    "                             edgecolor='0.5')\n",
    "        ax.add_collection(pc)\n",
    "\n",
    "        ax.set_title(r\"$\\int_a^b f(x)\\mathrm{d}x = %3.2f \\approx $ Sum of Rect. Areas = %3.2f\" \n",
    "                     %(self.integral, self.integral_approx), fontsize=20)\n",
    "\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.set_xticks((self.a, self.b))\n",
    "        ax.set_xticklabels(('$a$', '$b$'))\n",
    "        plt.show()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def evaluate_and_plot_rectangle_approx(self, a, b, n, rule, x_min, x_max, N=101, fignum=0):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        self.change_rectangles(n=n, rule=rule)\n",
    "        \n",
    "        self.set_integral_limits(a=a, b=b)\n",
    "        \n",
    "        self.compute_integral_approx()\n",
    "        \n",
    "        self.plot_rectangle_approx(x_min=x_min, x_max=x_max, N=N, fignum=fignum)\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rects = RectangleRule(f = lambda x: (x + 1) * (x - 5) * np.sin(3*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f out\n",
    "\n",
    "%matplotlib widget\n",
    "interact_manual(f_rects.evaluate_and_plot_rectangle_approx, \n",
    "         a = widgets.FloatSlider(value=0, min=-1, max=5, step=0.1),\n",
    "         b = widgets.FloatSlider(value=1, min=-1, max=5, step=0.1),\n",
    "         n = widgets.IntSlider(value=10, min=1, max=1000),\n",
    "         x_min = widgets.fixed(-1),\n",
    "         x_max = widgets.fixed(2),\n",
    "         rule=['left', 'right', 'middle'],\n",
    "         N = widgets.fixed(101),\n",
    "         fignum=widgets.fixed(0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid cyan\"> </hr>\n",
    "\n",
    "## <span style='background:rgba(0,255,255, 0.5); color:black'>Activity: Rectangle rules</span><a id='activity-rectangle-rules'></a>\n",
    "\n",
    "*For the sake of simplicity, this activity does not require the use of any classes.*\n",
    "\n",
    "Feel free to create many new code and markdown cells below as you work through this activity.\n",
    "\n",
    "- Create a wrapper function, `multiple_rect_approx`, which has all the same parameters as `compute_rect_rules` except that the `n` parameter is now assumed to be an *array* (or *list*) of integers containing different numbers of rectangles for which the approximate integrals should be computed. \n",
    "\n",
    "  This wrapper function should loop through all the values in the list of `n` values, call `compute_rect_rules` to obtain the associated approximate integral, and store all of the approximate integrals in a list that is returned by the wrapper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a number of different `lambda` functions including `f = lambda x: x`, `f = lambda x: x**2`, and at least one of your own choosing, compute the errors for the left-, right, and midpoint-rule approximations for `n=[10, 100, 1000]` for `a=0` and `b=1`. Store the errors as either a list or numpy array. \n",
    "\n",
    "    *Hint*: To compute the errors, you need to either know the exact value (or a very accurate approximation) of the integral of the function to compare to the rectangle rule approximations. Use the imported `quad` function from `scipy.integrate` as the \"exact\" value (it is a very good approximation in almost all cases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each of your different `lambda` functions, create a log-log plot with a legend that shows the errors for each rectangle rule approximation vs. the number of rectangles. A log-log plot of errors is useful for analyzing the rate of convergence of a method. We like to see the errors *decrease* as we *increase* the computational effort. Estimate the rate of convergence using the `np.polyfit` function as shown in the example above.\n",
    "\n",
    "   *Hint*: To use a log-log plot, everything must be non-negative, so you should use the `np.abs` function on the y-values of this plot as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comment on/interpret your results in the Markdown cell below. Some questions you should try to answer are the following. Which method appears to be most accurate/converge faster? Why do you think that is? *Hint:* Creating visualizations of the approximations of integrals with a small number of rectangles for the different methods may provide insight into how certain methods may be more likely to have \"canceling\" or \"off-setting\" errors within each rectangle. Some brief research online will also reveal the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid cyan\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Monte Carlo (MC) Integration](https://en.wikipedia.org/wiki/Monte_Carlo_integration) \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:rgba(255,255,0, 0.25); color:black'> Run the code cell below and click the \"play\" button to see the first recorded lecture associated with this notebook.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Running this cell with embed the short recorded lecture associated with this part of the notebook\n",
    "# 2. Press on the \"play\" button to start the video.\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('uTBCgEurJm4', width=800, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is to estimate $\\int_A f(x)$ using the *average* of a random sample of $f(x)$ values. \n",
    "\n",
    "The question is this: how do we generate a random sample of $f(x)$ values to do this?\n",
    "\n",
    "Well, we generate a random sample of $x$ values in the set $A$, and then evaluate the function $f$ at these random inputs. Then, we simply compute the sample average of $A$. \n",
    "\n",
    "Are there any sticky points to this?\n",
    "\n",
    "Well, a few simple examples will illustrate just about all you possibly need to know.\n",
    "\n",
    "Suppose $f(x)=5$ on $[0,1]$. From our previous example involving velocity and conceptualizing the integral of a real-valued function with a univariate input as the signed area between the curve and horizontal axis, we know that $\\int_{[0,1]} 5 = 5(1-0)=5$. So, this is what our MC estimate should be approximating.\n",
    "\n",
    "In fact, for any random sample of $x$-values between $[0,1]$, we will *always* get that the corresponding function values are *all* 5 because $f(x)$ is a constant 5 on this interval. So, what would the sample average be of these randomly sampled function values? Well, 5 of course! Whoa! The MC estimate is *exact* in this case. Great!\n",
    "\n",
    "What if $f(x)=5$ on $[0,2]$? So, all we have done is change the set from $[0,1]$ to $[0,2]$. We know the exact answer should now be $\\int_{[0,2]} 5 = 5(2-0)=10$. However, by the same reasoning, any random sample of $f(x)$ values will produce a sample average of $5$ not $10$. \n",
    "\n",
    "What if $f(x)=5$ on $[0,0.5]$? Again, the exact answer is $\\int_{[0,0.5]} 5 = 5(0.5-2)=2.5$, yet any sample average of $f(x)$ values will produce $5$ not $2.5$. \n",
    "\n",
    "So, what is going on? Well, we need to *weight* the sample average by the *size* of the set $A$. \n",
    "\n",
    "In summary, if $\\{x_i\\}_{i=1}^N \\subset A$ is a *uniform* random sample from the set $A$, and we let $\\mu(A)$ denote the *measure* (i.e., size) of $A$, then an MC estimate of the integral is given by\n",
    "$$\n",
    "    \\int_A f(x) \\approx \\mu(A)\\frac{1}{N}\\sum_{i=1}^N f(x_i).\n",
    "$$\n",
    "\n",
    "Let's play with this below and discuss what we are seeing.\n",
    "\n",
    "<span style='background:rgba(0,255,255, 0.5); color:black'> Suggested activity:</span> Add a useful docstring to `compute_1D_MC_approx` to describe the role of the various parameters. Add some doctests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_1D_MC_approx(f, a, b, n):\n",
    "    x_random = np.random.uniform(low=a, high=b, size=int(n))\n",
    "    mu_A = b-a  # mu_A=measure (size) of A\n",
    "    avg_func = np.mean(f(x_random))\n",
    "    MC_est = mu_A * avg_func\n",
    "    return (avg_func, MC_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Let's do some numerical experiments and analysis.***\n",
    "\n",
    "Below, we show how to\n",
    "\n",
    "1. Use the `compute_1D_MC_approx` function defined above and understand its variability due to random sampling.\n",
    "\n",
    "2. Analyze the rate of convergence (ROC).\n",
    "\n",
    "3. Create interactive visualizations of the `compute_1D_MC_approx` function that help us tell a story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: (x + 1) * (x - 5) * np.sin(3*x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These all look the same, but are different, why?\n",
    "int_approx  = compute_1D_MC_approx(f, a=2, b=4, n=100)[1]\n",
    "print(int_approx)\n",
    "int_approx  = compute_1D_MC_approx(f, a=2, b=4, n=100)[1]\n",
    "print(int_approx)\n",
    "int_approx  = compute_1D_MC_approx(f, a=2, b=4, n=100)[1]\n",
    "print(int_approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see above is an issue involving the random sampling of points between $[a,b]$ to generate an approximation of the average value of the function. As you can see by re-running the above code cell multiple times, there can be quite a bit of variability. Below, we compute 1000 approximations and visualize the results with a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 1000\n",
    "int_approx = np.zeros(num_trials)\n",
    "for i in range(num_trials):\n",
    "    int_approx[i] = compute_1D_MC_approx(f, a=2, b=4, n=100)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(int_approx)\n",
    "plt.axvline(quad(f, a=2, b=4)[0], color='k')  # Plot a vertical line where the \"exact\" value of the integral is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the histogram above, we see that the histogram appears to be centered around the exact value, so we compute the mean (sample average) of the estimates below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int_approx.mean())\n",
    "print(quad(f, a=2, b=4)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, while any single MC estimate may be \"bad\", the expected value (i.e., the mean) of all MC estimates is quite good. In fact, the MC method produces what is known as an *unbiased* estimator of the integral meaning that its expected value is exactly the integral we want. Unfortunately, the variance in this estimator (i.e., how much any single MC estimate may vary around the estimate) can be quite large. How do we reduce the variance? We increase the number of points used to estimate the average value of the function. We show this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can take a few seconds to run\n",
    "# Students should comment each line of code here and explain the shape of int_approx and what \n",
    "# is stored in the ij component of this array.\n",
    "num_trials = 1000\n",
    "ns = np.logspace(2, 4, num=3).astype(int)\n",
    "int_approx = np.zeros((3,num_trials))\n",
    "for i in range(3):\n",
    "    for j in range(num_trials):\n",
    "        int_approx[i,j] = compute_1D_MC_approx(f, a=2, b=4, n=ns[i])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "for i in range(3):\n",
    "    plt.hist(int_approx[i,:], alpha=1-0.2*i, label='n=' + str(ns[i]))\n",
    "plt.legend(fontsize=12)\n",
    "plt.axvline(quad(f, a=2, b=4)[0], color='k') # Plot a vertical line where the \"exact\" value of the integral is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the histograms above, we see that increasing `n` will reduce the variance in the MC estimates. In other words,  each individual MC estimate is more likely to be closer to its mean value. Since the mean values are all the same (the MC estimates are unbiased), this means that a larger `n` value is more likely to produce *accurate* estimates of the integral. \n",
    "\n",
    "It is more common to use the standard deviation to quantify variability in estimates around the mean value than the variance because it is in the same units as the mean value. The standard deviation is simply the square root of the variance. It can be computed using a built-in function within numpy as we show below where we analyze the rate of convergence (ROC) of MC estimates in terms of the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now visualize the convergence of the left-hand rule\n",
    "plt.figure()\n",
    "plt.loglog(ns, int_approx.std(axis=1))\n",
    "plt.xlabel('# of random samples', fontsize=12)\n",
    "plt.title('St.Dev. of MC Estimates vs. # of samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_estimate = np.polyfit(np.log(ns), np.log(int_approx.std(axis=1)), 1)[0]\n",
    "\n",
    "print(ROC_estimate) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above value is approximately -0.5, which is the theoretical rate guaranteed by the Central Limit Theorem (you should really take some probability theory and statistics classes is the lesson here). What this means is that for each order of magnitude increase in the number of samples, the standard deviation is decreased by *half* an order of magnitude.\n",
    "\n",
    "Is this worse than the left-, right-, or mid-point rules for the deterministic methods? Yes, yes it is. Except there is a huge caveat here. The geometric methods for approximating integrals only work in extremely low dimensions. Geometric or other deterministic \"quadrature\" or \"cubature\" methods for approximating integrals suffer from what is known as the curse of dimensionality (look this up). We will not dwell on this here other than to say that as the dimension goes way up, the quality of the deterministic estimates goes way down unless an exponentially increasing number of points are used to estimate the integral.\n",
    "\n",
    "The rate of convergence for the MC estimate is *independent* of dimension (although this does not quite tell the whole story, it is a big reason why random or pseudo-random approaches to estimating integrals are preferred in high-dimensions). \n",
    "\n",
    "Below, we create some visualizations to help capture the story above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_MC_1D(f, a, b, n, x_min, x_max):\n",
    "    avg_func, MC_est = compute_1D_MC_approx(f, a, b, n)\n",
    "        \n",
    "    ####### Everything below is for plotting\n",
    "    x = np.linspace(x_min, x_max, 101)\n",
    "    y = f(x)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, y, 'r', linewidth=2)\n",
    "\n",
    "    plt.axhline(0, linewidth=1, linestyle=':', c='k') #plot typical x-axis\n",
    "    \n",
    "    # Make the shaded region\n",
    "    ix = np.linspace(a, b, 101)\n",
    "    iy = f(ix)\n",
    "    verts = [(a, 0), *zip(ix, iy), (b, 0)]\n",
    "    poly = Polygon(verts, facecolor='0.9', edgecolor='0.5')\n",
    "    ax.add_patch(poly)\n",
    "    \n",
    "    # Make an \"average\" rectangle corresponding to the MC_est\n",
    "    verts = [(a, 0), (a, avg_func), (b, avg_func) , (b, 0)]\n",
    "    rect = Polygon(verts, facecolor='b', alpha=0.25, edgecolor='0.5')\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    ax.set_title(r\"$\\int_a^b f(x)\\mathrm{d}x \\approx \\frac{b-a}{N}\\sum_{i=1}^N f(x_i) =$ %3.2f\" %MC_est, fontsize=20)\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.set_xticks((a, b))\n",
    "    ax.set_xticklabels(('$a$', '$b$'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f out\n",
    "\n",
    "# Using an interact_manual widget so that we can re-run easily to observe\n",
    "# the variations in the MC estimates due to random sampling.\n",
    "\n",
    "interact_manual(plot_MC_1D, \n",
    "         f = widgets.fixed(lambda x: (x + 1) * (x - 5) * np.sin(3*x)),\n",
    "         a = widgets.FloatSlider(value=1, min=-1, max=5, step=0.1),\n",
    "         b = widgets.FloatSlider(value=2.5, min=-1, max=5, step=0.1),\n",
    "         n = widgets.IntSlider(value=1E2, min=10, max=1E5, step=10),\n",
    "         x_min = widgets.fixed(-1),\n",
    "         x_max = widgets.fixed(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid cyan\"> </hr>\n",
    "\n",
    "## <span style='background:rgba(0,255,255, 0.5); color:black'>Activity: Monte Carlo integration</span><a id='activity-MC'></a>\n",
    "\n",
    "Feel free to create many new code and markdown cells below as you work through this activity.\n",
    "\n",
    "- Complete the wrapper function, `multiple_1D_MC_approx`, in the code cell below except that we now assume `n` is a list of integers containing the different numbers of random points used to approximate the integral. The wrapper function also has an additional parameter `num_trials`, which is an `int` type that specifies the number of times (i.e., the number of trials) to repeat the approximations for each value in the list `n` values. The default `num_trials` is set to 10. \n",
    "    \n",
    "  The function should output a 2-dimensional numpy array of shape `(len(n),num_trials)` where the `[i,j]` component (in Python syntax) gives the (j+1)th MC approximation of the integral using `n[i]` random points.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_1D_MC_approx(f, a, b, n, num_trials=10):\n",
    "    \n",
    "    int_f_approx = np.zeros(( , )) #COMPLETE THIS PART TO INITIALIZE THE ARRAY TO ALL ZEROS\n",
    "        \n",
    "    for i in range(len(n)):\n",
    "        \n",
    "        for j in range(num_trials):\n",
    "            \n",
    "            int_f_approx[i,j] = compute_1D_MC_approx() #COMPLETE THIS PART\n",
    "            \n",
    "    return int_f_approx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a number of different `lambda` functions including  `f = lambda x: x`, `f = lambda x: x**2`, and at least one of your own choosing, compute the errors for the MC approximations of the integrals with `n=[int(1E1), int(1E2), int(1E3), int(1E4)]`, `a=0`, and `b=1`. For each function, create a numpy array of shape `(len(n),num_trials)` to store the errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each of your different `lambda` functions, create two separate log-log plots with a legend that shows the *means* and *variances* (over the number of trials) of the computed errors vs. the number of random points used in the MC approximations. For the means plot, you should compute the absolute values of the mean errors (not the mean of the absolute value) in order to get the plot to show correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comment on your results in the Markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid cyan\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if the set $A$ is complicated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:rgba(255,255,0, 0.25); color:black'> Run the code cell below and click the \"play\" button to see the first recorded lecture associated with this notebook.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Running this cell with embed the short recorded lecture associated with this part of the notebook\n",
    "# 2. Press on the \"play\" button to start the video.\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('PfIU7AK51Z8', width=800, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical built-in random number generators available in `numpy.random` or `scipy.stats` are great for generating random numbers/vectors in *nice* geometric sets like intervals in 1-D, rectangles in 2-D, rectangular boxes in 3-D, and generalizations of rectangular boxes in higher-dimensions. \n",
    "\n",
    "But, what if $A$ is not an interval or box-shaped? What if we can only describe $A$ in terms of relationships to other points or other geometric shapes? \n",
    "\n",
    "Well, we can do something referred to as accept-reject (sometimes just called rejection) sampling. \n",
    "\n",
    "At a conceptual level, imagine that we create a \"dart board\" out of a simple object (like a box) that *contains* the set $A$. The set $A$ is the \"target\" of the dart board. If we generate random numbers/vectors in the simple object (i.e., we \"throw darts at the board\") and *accept those that are inside of $A$* (i.e., we check if a \"dart hits the target\"), then we will have generated random samples within $A$. \n",
    "\n",
    "<span style='background:rgba(255,0,255, 0.25); color:black'> ***Key Points:*** <span>\n",
    "\n",
    "- The proprtion of \"darts\" that fall in $A$ (i.e., the target) times the measure of the circumscribing box (i.e., the dart board size) gives an estimate of the measure of $A$ (which we denote by $\\mu(A)$).\n",
    "    \n",
    "- We may have to throw a lot of darts to generate as many random samples in $A$ as we like.\n",
    "\n",
    "Let's illustrate when $A$ is a unit disk in $\\mathbb{R}^2$ that we fit into the dart board defined by the square $[-1,1]\\times[-1,1]$.\n",
    "    \n",
    "<span style='background:rgba(0,255,255, 0.5); color:black'> Suggested activity:</span> Add a useful docstring to `random_disk_darts` to describe the role of the various parameters. Add some doctests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_disk_darts(n):\n",
    "    #First throw darts at circumscribing square\n",
    "    darts = np.random.uniform(low=-1, high=1, size=(int(n),2))\n",
    "    \n",
    "    #check which darts hit the target: a disk called \"A\"\n",
    "    idx_in_A = []\n",
    "    idx_not_in_A = []\n",
    "    for i in range(n):\n",
    "        if np.sqrt((darts[i,0]-0)**2 + (darts[i,1]-0)**2) < 1:\n",
    "            idx_in_A.append(i)\n",
    "        else:\n",
    "            idx_not_in_A.append(i)\n",
    "            \n",
    "    mu_A_est = len(idx_in_A)/n * 4 # Estimates the area of A\n",
    "            \n",
    "    return darts, idx_in_A, idx_not_in_A, mu_A_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:rgba(0,255,255, 0.5); color:black'> Suggested activity:</span> Create a variant of the `random_disk_darts` function that uses a while-loop to generate `n` samples within $A$ and also returns the total `m` samples needed to generate these `n` samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_disk_darts(n):\n",
    "    darts, idx_in_A, idx_not_in_A, mu_A_est = random_disk_darts(n)\n",
    "    \n",
    "    ### Everything below is plotting\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    \n",
    "    ax.set_xlim([-1,1])\n",
    "    ax.set_ylim([-1,1])\n",
    "    ax.set_aspect(1)\n",
    "    \n",
    "    A = plt.Circle((0, 0), 1, color='r', alpha=0.1)\n",
    "    ax.add_artist(A)\n",
    "\n",
    "    ax.scatter(darts[idx_in_A,0], darts[idx_in_A,1], s=20, marker='x', c='k')    \n",
    "    ax.scatter(darts[idx_not_in_A,0], darts[idx_not_in_A,1], s=20, marker='o', c='b')\n",
    "\n",
    "    ax.set_title(r\"$\\mu(A)\\approx \\mu$(dart board)$\\times$(percent of darts in $A$) $\\approx$ %3.2f\" \n",
    "                 %mu_A_est, fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f out\n",
    "\n",
    "# Using an interact_manual widget so that we can re-run easily to observe\n",
    "# the variations in the MC estimates of the area due to random sampling.\n",
    "\n",
    "interact_manual(plot_random_disk_darts, \n",
    "                n = widgets.IntSlider(value=1E2, min=10, max=1E4, step=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid cyan\"> </hr>\n",
    "\n",
    "## <span style='background:rgba(0,255,255, 0.5); color:black'>Activity: Integration over the dart board</span><a id='activity-MC-darts'></a>\n",
    "\n",
    "- Based on the `random_disk_darts` function, create a new function, `my_MC_disk`, below that estimates the integral of a function $f$ over the unit disk. This function should have as inputs parameters `f` and `n` where `f` is the function to be integrated. It should return an estimate of the integral of `f` over the disk as well as the other outputs returned by `random_disk_darts`. \n",
    "\n",
    "  *Hint*: Two lines of code needed are:\n",
    "\n",
    " `avg_func = np.mean(f(darts[idx_in_A,:]))`\n",
    "\n",
    "  and \n",
    "\n",
    "  `int_f_approx = mu_A_est * avg_func`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run some tests for different `lambda` functions of your choosing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on the `plot_random_disk_darts` function, create a new function, `plot_MC_disk`, below that plots the darts that uses the `my_MC_disk` function to approximate the integral of a function `f` over the disk and plots the disk, darts that fall in/out of the disk, and displays the approximate integral of the function `f` as the title of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Demonstrate that your `plot_random_disk_darts` function works on some `lambda` functions of your choosing below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Recommended but not required:*** Try to create new functions `my_MC_ellipse` and `plot_MC_ellipse_darts` that do similar MC computations and visualizations, but over ellipses instead of disks. Demonstrate that these functions work as expected. You may find reviewing the formula for a standard ellipse useful in doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid cyan\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid cyan\"> </hr>\n",
    "\n",
    "## <span style='background:rgba(0,255,255, 0.5); color:black'>Activity: Summary</span> <a id='activity-summary'/>\n",
    "\n",
    "Summarize some of the key takeaways/points from this notebook in a list below and prepare a few code examples related to these takeaways/points in the code cells below. You need to have at least one example for each of your summary points and you need at least three summary points.\n",
    "\n",
    "In this notebook, we have seen the following:\n",
    "\n",
    "- [Your summary point 1 goes here]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- [Your summary point 2 goes here]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- [Your summary point 3 goes here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:5px solid cyan\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href='#Contents'>Click here to return to Notebook Contents</a>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
